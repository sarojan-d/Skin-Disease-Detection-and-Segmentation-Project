{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata = pd.read_csv('HAM10000_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for train and test sets\n",
    "os.makedirs('data/train/images', exist_ok=True)\n",
    "os.makedirs('data/train/labels', exist_ok=True)\n",
    "os.makedirs('data/val/images', exist_ok=True)\n",
    "os.makedirs('data/val/labels', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to copy images and masks to respective directories\n",
    "def copy_files(df, subset):\n",
    "    for index, row in df.iterrows():\n",
    "        image_file = f'HAM10000_combined/{row[\"image_id\"]}.jpg'\n",
    "        mask_file = f'HAM10000_segmentations/{row[\"image_id\"]}_segmentation.png'\n",
    "        if os.path.exists(image_file) and os.path.exists(mask_file):\n",
    "            shutil.copy(image_file, f'data/{subset}/images/{row[\"image_id\"]}.jpg')\n",
    "            shutil.copy(mask_file, f'data/{subset}/labels/{row[\"image_id\"]}_segmentation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files to train and validation directories\n",
    "copy_files(train_df, 'train')\n",
    "copy_files(val_df, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saroj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\albumentations\\core\\validation.py:45: UserWarning: This augmenter is very slow. Try to use ``ElasticTransformation`` instead, which is at least 10x faster.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define augmentations\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.Flip(),\n",
    "    A.Transpose(),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(),\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.2),\n",
    "        A.MedianBlur(blur_limit=3, p=0.1),\n",
    "        A.Blur(blur_limit=3, p=0.1),\n",
    "    ], p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=20, p=0.2),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p=0.3),\n",
    "        A.GridDistortion(p=0.1),\n",
    "        A.PiecewiseAffine(p=0.3),\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2),\n",
    "        A.Sharpen(),\n",
    "        A.Emboss(),\n",
    "        A.RandomBrightnessContrast(),\n",
    "    ], p=0.3),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentations and save augmented images\n",
    "def augment_and_save(image_path, mask_path, save_dir, transform):\n",
    "    if os.path.exists(image_path) and os.path.exists(mask_path):\n",
    "        image = np.array(Image.open(image_path))\n",
    "        mask = np.array(Image.open(mask_path))\n",
    "        augmented = transform(image=image, mask=mask)\n",
    "        aug_image = Image.fromarray(augmented['image'])\n",
    "        aug_mask = Image.fromarray(augmented['mask'])\n",
    "        aug_image.save(os.path.join(save_dir, 'images', os.path.basename(image_path)))\n",
    "        aug_mask.save(os.path.join(save_dir, 'labels', os.path.basename(mask_path)))\n",
    "    else:\n",
    "        print(f\"File not found: {image_path} or {mask_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentations to train set\n",
    "for index, row in train_df.iterrows():\n",
    "    image_path = f'data/train/images/{row[\"image_id\"]}.jpg'\n",
    "    mask_path = f'data/train/labels/{row[\"image_id\"]}_segmentation.png'\n",
    "    augment_and_save(image_path, mask_path, 'data/train', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_save(image_path, mask_path, save_dir, transform):\n",
    "    # Load image and mask\n",
    "    image = Image.open(image_path)\n",
    "    mask = Image.open(mask_path)\n",
    "    \n",
    "    # Convert PIL images to Numpy arrays\n",
    "    image_np = np.array(image)\n",
    "    mask_np = np.array(mask)\n",
    "    \n",
    "    # Apply transformations (assuming transform is a function that works with Numpy arrays)\n",
    "    augmented_image, augmented_mask = transform(image_np, mask_np)\n",
    "    \n",
    "    # Convert back to PIL images if needed\n",
    "    augmented_image = Image.fromarray(augmented_image)\n",
    "    augmented_mask = Image.fromarray(augmented_mask)\n",
    "    \n",
    "    # Save augmented images and masks\n",
    "    augmented_image.save(f'{save_dir}/augmented_{os.path.basename(image_path)}')\n",
    "    augmented_mask.save(f'{save_dir}/augmented_{os.path.basename(mask_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
