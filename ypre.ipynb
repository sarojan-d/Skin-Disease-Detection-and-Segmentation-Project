{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ground truth CSV file\n",
    "df = pd.read_csv('HAM10000_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "#import imgaug.augmenters as iaa\n",
    "from glob import glob\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import OneOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "image_src_dir = 'HAM10000_combined'\n",
    "mask_src_dir = 'HAM10000_segmentations'\n",
    "image_dest_base_dir = 'data/images'\n",
    "mask_dest_base_dir = 'data/masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from class names to numeric labels\n",
    "class_mapping = {\n",
    "    'mel': 1,\n",
    "    'nv': 2,\n",
    "    'bcc': 3,\n",
    "    'akiec': 4,\n",
    "    'bkl': 5,\n",
    "    'df': 6,\n",
    "    'vasc': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class-specific folders\n",
    "for label in class_mapping.values():\n",
    "    os.makedirs(os.path.join(image_dest_base_dir, str(label)), exist_ok=True)\n",
    "    os.makedirs(os.path.join(mask_dest_base_dir, str(label)), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images and masks to their respective class folders\n",
    "for _, row in df.iterrows():\n",
    "    img_name = row['image_id']\n",
    "    img_class = class_mapping[row['dx']]\n",
    "\n",
    "    img_src_path = os.path.join(image_src_dir, img_name + '.jpg')\n",
    "    mask_src_path = os.path.join(mask_src_dir, img_name + '_segmentation.png')\n",
    "    \n",
    "    img_dest_path = os.path.join(image_dest_base_dir, str(img_class), img_name + '.jpg')\n",
    "    mask_dest_path = os.path.join(mask_dest_base_dir, str(img_class), img_name + '_segmentation.png')\n",
    "    \n",
    "    #shutil.copy(img_src_path, img_dest_path)\n",
    "    #shutil.copy(mask_src_path, mask_dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images_and_masks(image_paths, mask_paths, target_count):\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=20, p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "            A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=0.5),\n",
    "        ], p=0.5)\n",
    "    ])\n",
    "\n",
    "    count = len(image_paths)\n",
    "    while count < target_count:\n",
    "        idx = count % len(image_paths)\n",
    "        image = cv2.imread(image_paths[idx])\n",
    "        mask = cv2.imread(mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        augmented = transform(image=image, mask=mask)\n",
    "        aug_image = augmented['image']\n",
    "        aug_mask = augmented['mask']\n",
    "\n",
    "        aug_img_path = image_paths[idx].replace('.jpg', f'_aug{count}.jpg')\n",
    "        aug_mask_path = mask_paths[idx].replace('_segmentation.png', f'_segmentation_aug{count}.png')\n",
    "\n",
    "        cv2.imwrite(aug_img_path, aug_image)\n",
    "        cv2.imwrite(aug_mask_path, aug_mask)\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment data for each class based on the new target distribution\n",
    "class_counts = {\n",
    "    1: 3000,  # mel\n",
    "    2: 10000, # nv\n",
    "    3: 2000,  # bcc\n",
    "    4: 1500,  # akiec\n",
    "    5: 3000,  # bkl\n",
    "    6: 1000,  # df\n",
    "    7: 1000   # vasc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls, target_count in class_counts.items():\n",
    "    image_paths = glob(os.path.join(image_dest_base_dir, str(cls), '*.jpg'))\n",
    "    mask_paths = glob(os.path.join(mask_dest_base_dir, str(cls), '*_segmentation.png'))\n",
    "    \n",
    "    augment_images_and_masks(image_paths, mask_paths, target_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in range(1, 8):\n",
    "    mask_paths = glob(os.path.join(mask_dest_base_dir, str(cls), '*_segmentation.png'))\n",
    "    for mask_path in mask_paths:\n",
    "        img_name = os.path.basename(mask_path).replace('_segmentation.png', '.jpg')\n",
    "        annotations.append({\n",
    "            'image': img_name,\n",
    "            'class': cls,\n",
    "            'mask': mask_path\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotations to a JSON file\n",
    "with open('annotations.json', 'w') as f:\n",
    "    json.dump(annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations\n",
    "with open('annotations.json', 'r') as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_val, test = train_test_split(annotations, test_size=0.2, stratify=[a['class'] for a in annotations])\n",
    "train, val = train_test_split(train_val, test_size=0.2, stratify=[a['class'] for a in train_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the splits\n",
    "with open('train_annotations.json', 'w') as f:\n",
    "    json.dump(train, f)\n",
    "\n",
    "with open('val_annotations.json', 'w') as f:\n",
    "    json.dump(val, f)\n",
    "\n",
    "with open('test_annotations.json', 'w') as f:\n",
    "    json.dump(test, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
